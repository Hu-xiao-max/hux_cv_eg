<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8">
<title>hux_cv_site</title>
</head>


<body>
    <h1>Xiao Hu's CV</s></h1>
    <img src="./images/hx.png" width="258" height="258" />
</body>


<body>
    <br><!-- 换行 -->
    <a href="https://hu-xiao-max.github.io/video.xiaohu/">Project Video</a>
    <br>
    Tel:+1 857-788-6299 | E-mail:xiao.h1@northeastern.edu
    
</body>


<!-- <body>

    <b>加粗文本</b><br><br>
    <i>斜体文本</i><br><br>
    <code>电脑自动输出</code><br><br>
    这是 <sub> 下标</sub> 和 <sup> 上标</sup>
    
</body> -->

<!-- 背景颜色和字体颜色 -->
<!-- <body style="background-color:white;">

</body>

<body>
    <h2 style="background-color:red;">这是一个标题</h2>
    <p style="background-color:green;">这是一个段落。</p>
</body> -->


<!-- 居中对齐 -->
<!-- <body>

    <h1 style="text-align:center;">居中对齐的标题</h1>
    <p>这是一个段落。</p>
    
</body> -->

<!-- 教育 -->


<body>
    <h2>Eduction</h2>
    <hr>
    <b>Henan Polytechnic University </b>|2016-2020 | Bachelor<br>
    Intelligent system<br>
    <br>
    
    <b>ShenZhen University </b>|2021-2024 |Master<br>
    Intelligent system<br>
    <br>

    <b>South China University of Technology </b>|2024-2025 |PhD<br>
    Control Science and engineering<br>
    <br>

    <b>Northeastern University</b>|2025-Now (Fellowship) |PhD <br>
    Data & System<br>
    <br>

    <strong>Mentor</strong><br>
    <hr>
    XiangSheng Chen(Academician of the Chinese Academy of Engineering)<br>
    Lei Zhang(IEEE Fellow)<br>
    H. Ma<br>
    Gilbert Ye<br>

    

    

</body>


<body>
    <h2>Work</h2>
    <hr>
    <b>IDEA Guangdong-Hong Kong-Macao Greater Bay Area Digital Economy Research Institute </b> <br> 
    2021-2022 | Robotics Researcher (Intern) mentor: Dr. Zhang Lei <br> <br>

    <b>Xpeng Robotics </b> <br>
    2022-2023 | Robotic Arm Algorithm R&D Engineer (Intern) mentor: Dr. Chen Xiangyu
    <br> <br>

    <b>Tencent Robotics X </b> <br>
    2023-2024 | Assistant Researcher (Intern)  mentor: Dr. Huang Bidan

    <br> <br>

    <b>Pudu Robotics X Lab </b> <br>
    2024-2025 | Robotics Algorithm Engineer(full-time)

</body>

<h2>Project</h2>
<hr>
<p style="font-family:arial;color:blue;font-size:20px;">Dexterous Manipulation Based on Tactile Sensing</p>
2023.6-now<br>
Conducting dexterous manipulation：<br>
&deg;Tactile-based grasping.<br>
&deg;Migration to real robot.<br>
&deg;Sim2real parameter optimization and adjustment.<br>
&deg;Reinforcement learning in Mujoco using tactile feedback.<br>
&deg;Persistent testing and maintenance of tactile sensors.<br>


<p style="font-family:arial;color:blue;font-size:20px;">PointnetGPD Grasping Algorithm Closed-loop</p>
2022.6-2022.12<br>
To implement closed-loop grasping network, it is necessary to create a grasping dataset for the corresponding scene, and the responsible work is as follows：<br>
&deg;Develop automatic object image capturing function based on Kinova Jaco2.<br>
&deg;Set control points for photos and use Nerf to generate 3D models of objects.<br>
&deg;Generate grasping annotations for the generated 3D models using GPD.<br>
&deg;Develop simulated depth map generation function based on pybullet.<br>
&deg;Automatically combine the above data into a dataset.<br>

<p style="font-family:arial;color:blue;font-size:20px;">Grasping Object Assembly</p>
2022.12-2023.03<br>
Insight is a grasping dataset with many repetitive parts in both positive and negative sample models, so a new method of assembling objects is proposed to solve this problem:<br>
&deg;Develop large-scale grasping label screening function based on Isaac Gym.<br>
&deg;Design an edge catcher to accelerate computation.<br>
&deg;Design a shape filter to screen out consistent shapes.<br>
&deg;Write papers using Latex, conduct experiments, make videos and submit papers.<br>

<p style="font-family:arial;color:blue;font-size:20px;">AnyGrasp Testing</p>
2023.03-2023.04<br>
Test AnyGrasp:<br>
&deg;Learn Flexiv robotic arm operation.<br>
&deg;Learn Graspnet.<br>
&deg;Test AnyGrasp performance and find corner cases.<br>
&deg;Clarify the composition of Graspnet-1billion dataset and prepare for closed-loop.<br>
&deg;Develop graspnet grasping annotation function.<br>


<p style="font-family:arial;color:blue;font-size:20px;">Robotics Center Platform Construction</p>
2022.06-2023.01<br>
Assist in the construction of the robotics center：<br>
&deg;Develop an object grasping demo based on YOLO algorithm for the physical robotic arm.<br>
&deg;Learn Vrep simulation platform and create demos.<br>
&deg;Learn and organize ROS.<br>
&deg;Learn to use supercomputing platform.<br>


<p style="font-family:arial;color:blue;font-size:20px;">Robotics Competition Project</p>
2017.06-2019.08<br>
Serve as team leader and undertake corresponding tasks：<br>
&deg;Design and create robot structure diagrams using Soildworks.<br>
&deg;Purchase materials according to the structure diagram, use laser cutting for aluminum plates, bend, and assemble corresponding accessories.<br>
&deg;Design and debug actions for the assembled robot.<br>
&deg;Debug at the competition site and handle emergency situations such as control board burning.<br>


<body>
    <h2>Award</h2>
    <hr> 2018 China Robot Competition Dance Group First Prize<br> 
    2018 National College Student Mathematical Modeling Competition Provincial First Prize<br> 
    2019 National College Student Electronic Design Competition Provincial First Prize<br> 
    2017 China Engineering Robot Competition Narrow Foot Race Group Second Prize<br> 
    Shenzhen University Graduate First-class Scholarship<br>

</body>

<body>
    <h2>Service</h2>
    <hr>
    Reviewer of ICRA IROS
</body>


<body>
    <h2>Publication</h2>
    <hr>
    <b>Xiao Hu </b>, & Gilbert Ye. 'Teleoperation of Semi-humanoid
    with dexterous hand' i3CE 2025 <br>
    <b>Xiao Hu.</b>, & Gilbert Ye. (2025). Tactile-based reinforcement learning for adaptive grasping under observation uncertainties. 
    IEEE International Conference on Robotics and Automation (ICRA 2025).<br>
    <b>Xiao Hu.</b>. Autonomous positioning and walking trajectory planning method for 
    construction robots. Computer Campus 2021.<br>
    

    


</body>



</html>
